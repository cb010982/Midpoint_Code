# -*- coding: utf-8 -*-
"""Final MealRec.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wMIfuarKGKJcMo7TWZEtxqeFHo5cK6WV
"""

import pandas as pd
import json
import zipfile
import re
import os
import zipfile
!pip install scikit-surprise
from surprise import SVD, Dataset, Reader
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from google.colab import files
warnings.filterwarnings('ignore')
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from surprise import accuracy
import numpy as np
from collections import defaultdict
from surprise import KNNBasic, accuracy
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import mean_squared_error
from surprise import SVD, KNNBasic, Dataset, Reader, accuracy
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.utils import resample
from IPython.display import display
from surprise.model_selection import cross_validate
from surprise import SVD, KNNBasic, Dataset, Reader
from tabulate import tabulate
from sklearn.model_selection import KFold
from surprise.model_selection import GridSearchCV
from sklearn.model_selection import KFold, ParameterGrid
from surprise.accuracy import rmse, mae

"""# Load the Dataset"""

#Load txt files
user_meal_train = pd.read_csv("user_meal_train.txt", sep="\t", header=None, names=["user_id", "meal_id"])
user_meal_tune = pd.read_csv("user_meal_tune.txt", sep="\t", header=None, names=["user_id", "meal_id"])
user_meal_test = pd.read_csv("user_meal_test.txt", sep="\t", header=None, names=["user_id", "meal_id"])
meal_course = pd.read_csv("meal_course.txt", sep="\t", header=None, names=["meal_id", "course_id"])
course_category = pd.read_csv("course_category.txt", sep="\t", header=None, names=["course_id", "category_id"])
user2index = pd.read_csv("user2index.txt", sep="\t", header=None, names=["user_id", "index"])
course2index = pd.read_csv("course2index.txt", sep="\t", header=None, names=["course_id", "index"])
user_course_txt = pd.read_csv("user_course.txt", sep="\t", header=None, names=["user_id", "course_id"])

#  Extract & Load Course data from course.zip
try:
    with zipfile.ZipFile("course.zip", "r") as zip_ref:
        zip_ref.extractall("extracted_course")
    course = pd.read_csv("extracted_course/course.csv")
    print(" Successfully loaded course metadata.")
except Exception as e:
    print(f" Error extracting course.zip: {e}")

#  Extract & Load User-Course data from user_course.zip
try:
    with zipfile.ZipFile("user_course.zip", "r") as zip_ref:
        zip_ref.extractall("extracted_user_course")
    user_course = pd.read_csv("extracted_user_course/user_course.csv")
    print(" Successfully loaded user-course metadata.")
except Exception as e:
    print(f" Error extracting user_course.zip: {e}")

print("\n User-Meal Train Data Preview:")
print(user_meal_train.head())

print("\n User-Meal Tune Data Preview:")
print(user_meal_tune.head())

print("\n User-Meal Test Data Preview:")
print(user_meal_test.head())

print("\n Meal-Course Mapping Preview:")
print(meal_course.head())

print("\n Course Metadata Preview:")
print(course.head())

print("\n User-Course Interactions (TXT) Preview:")
print(user_course_txt.head())

print("\n User-Course Metadata Preview:")
print(user_course.head())

print("\n Course-Category Preview:")
print(course_category.head())

"""# Analyse Dataset"""

user_course_df = pd.read_csv("user_course.csv")
print(" Dataset Shape:", user_course_df.shape)

print("\n Column Names:", user_course_df.columns.tolist())

# Check data types and missing values
print("\n Dataset Info:")
print(user_course_df.info())

# Check for missing values
print("\n Missing Values Per Column:\n", user_course_df.isnull().sum())

#  Check for duplicate values
print("\n Duplicate Rows Count:", user_course_df.duplicated().sum())

# statistics for numerical columns
print("\n Basic Statistics:\n", user_course_df.describe())

print("\n First 5 Rows of Dataset:")
print(user_course_df.head())

"""# Exploratory Data Analysis - EDA"""

# Distribution of Ratings
plt.style.use("dark_background")
plt.figure(figsize=(8,5))
sns.countplot(x=user_course_df['rating'], palette="cool", edgecolor="white")
plt.title("Distribution of Ratings in user_course.csv", fontsize=14, color="white")
plt.xlabel("Rating (1-5)", fontsize=12, color="white")
plt.ylabel("Count", fontsize=12, color="white")
plt.grid(color="gray", linestyle="dashed", linewidth=0.5)
plt.show()

# Number of Interactions Per User
plt.style.use("dark_background")
user_interactions = user_course_df.groupby('user_id')['course_id'].count()
plt.figure(figsize=(8,5))
sns.histplot(user_interactions, bins=50, kde=True, color="cyan", edgecolor="white")
plt.title("Number of Interactions Per User", fontsize=14, color="white")
plt.xlabel("Number of Courses Interacted With", fontsize=12, color="white")
plt.ylabel("Number of Users", fontsize=12, color="white")
plt.grid(color="gray", linestyle="dashed", linewidth=0.5)
plt.show()

# Number of Interactions Per Course
plt.style.use("dark_background")
course_interactions = user_course_df.groupby('course_id')['user_id'].count()
plt.figure(figsize=(8,5))
sns.histplot(course_interactions, bins=50, kde=True, color="orange", edgecolor="white")
plt.title("Number of Interactions Per Course", fontsize=14, color="white")
plt.xlabel("Number of Users Interacting", fontsize=12, color="white")
plt.ylabel("Number of Courses", fontsize=12, color="white")
plt.grid(color="gray", linestyle="dashed", linewidth=0.5)
plt.show()

"""# Preprocessing"""

#Remove date last modified column
user_course_df = pd.read_csv("user_course.csv")
if 'dateLastModified' in user_course_df.columns:
    user_course_df.drop(columns=['dateLastModified'], inplace=True)

user_course_df.to_csv("user_course_clean.csv", index=False)
print("\n First 5 Rows After Removing `dateLastModified`:\n")
print(user_course_df.head())

# Convert ratings to binary values (4 → 0, 5 → 1) to show like and dislike rather rating 4 and 5
user_course_df = pd.read_csv("user_course_clean.csv")
user_course_df['rating'] = user_course_df['rating'].map({4: 0, 5: 1})
user_course_df.to_csv("user_course_binary.csv", index=False)
print("\n First 5 Rows After Rating Transformation:\n")
print(user_course_df.head())

#Ensure `user_id` and `course_id` are integers
user_course_df = pd.read_csv("user_course_binary.csv")
user_course_df['user_id'] = pd.to_numeric(user_course_df['user_id'], errors='coerce').astype('Int64')
user_course_df['course_id'] = pd.to_numeric(user_course_df['course_id'], errors='coerce').astype('Int64')

#  Drop rows with missing IDs
user_course_df.dropna(subset=['user_id', 'course_id'], inplace=True)

#  Convert IDs to `int64`
user_course_df['user_id'] = user_course_df['user_id'].astype('int64')
user_course_df['course_id'] = user_course_df['course_id'].astype('int64')

user_course_df.to_csv("user_course_fixed.csv", index=False)

print("\n First 5 Rows After Fixing ID Formatting:\n")
print(user_course_df.head())

try:
    with zipfile.ZipFile("course.zip", "r") as zip_ref:
        zip_ref.extractall("extracted_course")
    course_df = pd.read_csv("extracted_course/course.csv")
    print(" Successfully loaded course metadata.")
except Exception as e:
    print(f" Error extracting course.zip: {e}")


print("\n Course Metadata Preview:\n")
print(course_df.head())

try:
    with zipfile.ZipFile("course.zip", "r") as zip_ref:
        zip_ref.extractall("extracted_course")
    course_df = pd.read_csv("extracted_course/course.csv")
    print("Successfully loaded course metadata.")
except Exception as e:
    print(f" Error extracting course.zip: {e}")

# Function to extract nutrition data using regex
def extract_nutrition_values(nutrition_data):
    try:
        if pd.isna(nutrition_data) or not isinstance(nutrition_data, str):
            return {"calories": None, "sugar": None, "fiber": None}

        calories_match = re.search(r"'calories'\s*:\s*{[^}]*'amount'\s*:\s*([\d.]+)", nutrition_data)
        sugar_match = re.search(r"'sugars'\s*:\s*{[^}]*'amount'\s*:\s*([\d.]+)", nutrition_data)
        fiber_match = re.search(r"'fiber'\s*:\s*{[^}]*'amount'\s*:\s*([\d.]+)", nutrition_data)
        calories = float(calories_match.group(1)) if calories_match else None
        sugar = float(sugar_match.group(1)) if sugar_match else None
        fiber = float(fiber_match.group(1)) if fiber_match else None

        return {"calories": calories, "sugar": sugar, "fiber": fiber}

    except Exception as e:
        print(f" Error processing: {nutrition_data[:100]} -> {e}")
        return {"calories": None, "sugar": None, "fiber": None}

nutrition_details = course_df["nutritions"].apply(extract_nutrition_values)

nutrition_df = pd.DataFrame(nutrition_details.tolist())

course_df = pd.concat([course_df.drop(columns=["nutritions"], errors="ignore"), nutrition_df], axis=1)
course_df.to_csv("extracted_course/course_cleaned.csv", index=False)
print("\n Course Metadata After Extracting Nutrition Info:\n")
print(course_df[["course_id", "course_name", "calories", "sugar", "fiber"]].head())

# Function to Extract Ingredients
def extract_ingredients(ingredients_data):
    try:
        if pd.isna(ingredients_data) or not isinstance(ingredients_data, str):
            return None
        return re.sub(r'\^', ', ', ingredients_data)
    except Exception as e:
        print(f" Error processing ingredients: {e}")
        return None

# Function to Extract Cooking Directions
def extract_cooking_directions(directions_data):
    try:
        if pd.isna(directions_data) or not isinstance(directions_data, str):
            return None

        cleaned_text = re.sub(r"^{'directions': u'|'}$", '', directions_data)

        return cleaned_text.replace("\\n", " ").replace("\n", " ").strip()

    except Exception as e:
        print(f" Error processing cooking directions: {e}")
        return None


course_df["ingredients"] = course_df["ingredients"].apply(extract_ingredients)
course_df["cooking_directions"] = course_df["cooking_directions"].apply(extract_cooking_directions)

course_df.to_csv("extracted_course/course_cleaned.csv", index=False)
print("\n Course data saved after processing\n")

print("\n Cooking Directions Preview After Extractions:\n")
print(course_df[["course_id", "course_name", "cooking_directions", "ingredients"]].head())

course_df = pd.read_csv("extracted_course/course_cleaned.csv")
user_course_df = pd.read_csv("user_course_fixed.csv")

# Merge user-course interactions with course metadata
merged_df = user_course_df.merge(course_df, on="course_id", how="left")

print("\n Merged Course & User Data Preview:\n")
print(merged_df.head())

# Remove unecesary columns
merged_df = merged_df.drop(columns=["reviews", "tags", "review_nums", "aver_rate"], errors="ignore")
num_rows = merged_df.shape[0]
print("\n Updated dataset after removing reviews, tags, review_nums,aver_rate")
print(f" Number of rows: {num_rows}")
print(merged_df.head())

print(" Sugar Statistics:\n")
print(merged_df["sugar"].describe())

plt.figure(figsize=(8,5))
plt.hist(merged_df["sugar"], bins=50, color="blue", alpha=0.7, edgecolor="black")
plt.xlabel("Sugar Content")
plt.ylabel("Number of Meals")
plt.title("Updated Distribution of Sugar Levels in Meals")
plt.show()

# Distribution of Ratings
plt.figure(figsize=(8,5))
sns.countplot(x=merged_df['rating'], palette="cool", edgecolor="white")
plt.title("Distribution of Ratings", fontsize=14)
plt.xlabel("Rating (0 = disliked, 1 = liked)", fontsize=12)
plt.ylabel("Count", fontsize=12)
plt.show()

# Top 10 Most Popular Courses
top_courses = merged_df["course_name"].value_counts().head(10)
plt.figure(figsize=(10,6))
sns.barplot(y=top_courses.index, x=top_courses.values, palette="magma")
plt.title("Top 10 Most Popular Meals", fontsize=14)
plt.xlabel("Number of Interactions", fontsize=12)
plt.ylabel("Meal Name", fontsize=12)
plt.show()

# Average Calories per Category
category_nutrition = merged_df.groupby("category")["calories"].mean().sort_values()
plt.figure(figsize=(10,6))
sns.barplot(y=category_nutrition.index, x=category_nutrition.values, palette="coolwarm")
plt.title("Average Calories per Meal Category", fontsize=14)
plt.xlabel("Average Calories", fontsize=12)
plt.ylabel("Meal Category", fontsize=12)
plt.show()

sugar_threshold = 30

#  Remove meals with sugar > threshold
filtered_df = merged_df[merged_df["sugar"] <= sugar_threshold]

# Save the cleaned dataset
filtered_df.to_csv("filtered_meal_data.csv", index=False)

# Show the number of meals removed
print(f" Original dataset had {len(merged_df)} meals")
print(f" Filtered dataset now has {len(filtered_df)} meals")
print(f" Removed {len(merged_df) - len(filtered_df)} high-sugar meals")
print("\n Cleaned Data Preview:")
print(filtered_df.head())

# covert the categories: appetisers, main-dish, desserts to 0, 1,2 on the merged dataset
category_mapping = {'appetizer': 0, 'main-dish': 1, 'dessert': 2}
filtered_df['category'] = filtered_df['category'].map(category_mapping)
print(filtered_df.head())

# Initialize MinMaxScaler between 0 and 1 for the calories, sugar and fiber
scaler = MinMaxScaler()
filtered_df[["calories", "sugar", "fiber"]] = scaler.fit_transform(filtered_df[["calories", "sugar", "fiber"]])
print("\n Normalized Data Preview:\n")
print(filtered_df.head())

#  Download the file
merged_csv = filtered_df.to_csv(index=False)
with open("filtered_df.csv", "w") as file:
    file.write(merged_csv)
files.download("filtered_df.csv")
print(" Merged dataset downloaded successfully!")

file_path = "filtered_df.csv"
df = pd.read_csv(file_path)
print(df.head())
plt.figure(figsize=(8,5))
plt.hist(df["sugar"], bins=50, color="blue", alpha=0.7, edgecolor="black")
plt.xlabel("Sugar Content (grams)")
plt.ylabel("Number of Meals")
plt.title("Distribution of Sugar Levels in Meals")
plt.show()

# Calculate percentage distribution in ratings
df = pd.read_csv("filtered_df.csv")
if "rating" in df.columns:
    print(df["rating"].value_counts())
    like_ratio = df["rating"].value_counts(normalize=True) * 100
    print("\nPercentage distribution of Likes and Dislikes:")
    print(like_ratio)
else:
    print(" 'rating' column not found. Check the dataset structure.")

# Count number of ratings per user
user_rating_counts = df.groupby("user_id")["rating"].value_counts().unstack().fillna(0)
print(" Unique Users:", user_rating_counts.shape[0])
print("\n Average Likes per User:", user_rating_counts[1.0].mean())
print("Average Dislikes per User:", user_rating_counts[0.0].mean())
print("\n First 5 Users' Rating Distribution:")
print(user_rating_counts.head())

# Function to balance likes/dislikes for each user
def balance_user_ratings(user_df):
    rating_counts = user_df["rating"].value_counts()

    # Check if either likes or dislikes are missing for the user
    if len(rating_counts) < 2:
        return user_df

    # If both likes and dislikes are present, proceed with balancing
    min_count = min(rating_counts)
    return user_df.groupby("rating").apply(lambda x: x.sample(min_count)).reset_index(drop=True)

# Apply balancing per user
balanced_df = df.groupby("user_id", group_keys=False).apply(balance_user_ratings)

balanced_df.to_csv("balanced_filtered_df.csv", index=False)
print(f" Ratings balanced per user.The dataset now contains {len(balanced_df)} interactions.")

# Load balanced dataset
balanced_df = pd.read_csv("balanced_filtered_df.csv")

# Check the overall count of likes and dislikes
print("\n Overall Ratings Distribution:")
print(balanced_df["rating"].value_counts())

# Calculate percentage distribution
like_ratio = balanced_df["rating"].value_counts(normalize=True) * 100
print("\n Percentage Distribution of Likes and Dislikes:")
print(like_ratio)

# Check per-user balance
user_rating_counts = balanced_df.groupby("user_id")["rating"].value_counts().unstack().fillna(0)

print("\n Unique Users:", user_rating_counts.shape[0])
print("\n Average Likes per User:", user_rating_counts[1.0].mean())
print(" Average Dislikes per User:", user_rating_counts[0.0].mean())
print("\n First 5 Users' Rating Distribution (After Balancing):")
print(user_rating_counts.head())

df = pd.read_csv("balanced_filtered_df.csv")

# Display first few rows
print(df.head())

# Check for missing values
print("\n Missing Values Check:")
print(df.isnull().sum())

# Show any rows with missing values
print("\n Rows with Missing Values:")
print(df[df.isnull().any(axis=1)])

"""# Split Test and Train"""

# Selecting only necessary columns for training
df_filtered = df[["user_id", "course_id", "rating"]]

# Splitting into 80% training and 20% testing
train_data, test_data = train_test_split(df_filtered, test_size=0.2, random_state=42, stratify=df_filtered["user_id"])

# Save the split datasets
train_data.to_csv("train_data.csv", index=False)
test_data.to_csv("test_data.csv", index=False)

print(f" Train-Test Split Done")
print(f" Train Size: {len(train_data)}, Test Size: {len(test_data)}")

# Load train and test data
train_data = pd.read_csv("train_data.csv")
test_data = pd.read_csv("test_data.csv")

# Show dataset sizes
print(f" Train Dataset Size: {len(train_data)}")
print(f" Test Dataset Size: {len(test_data)}")

# Check the first few rows
print("\n Train Data Preview:")
print(train_data.head())

print("\n Test Data Preview:")
print(test_data.head())

"""# Model Training

### SVD & KNN
"""

# Load train and test data
train_data = pd.read_csv("train_data.csv")
test_data = pd.read_csv("test_data.csv")

reader = Reader(rating_scale=(0, 1))

# Load train data into Surprise
trainset = Dataset.load_from_df(train_data[["user_id", "course_id", "rating"]], reader).build_full_trainset()
testset = list(test_data[["user_id", "course_id", "rating"]].itertuples(index=False, name=None))

print("Data successfully formatted for Surprise library")

# Define models
models = {
    "SVD": SVD(),
    "KNN": KNNBasic(sim_options={'name': 'pearson_baseline', 'user_based': True})
}

# Function to train & evaluate a model
def train_and_evaluate(model, model_name, trainset, testset):
    # Train model
    model.fit(trainset)
    print(f"\n{model_name} Model Training Completed")

    predictions = model.test(testset)

    rmse = accuracy.rmse(predictions)
    mae = accuracy.mae(predictions)
    mse = rmse ** 2

    print(f"{model_name} Model Evaluation Completed")
    print(f"MSE: {mse:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print(f"MAE: {mae:.4f}\n")

    return {"Model": model_name, "MSE": mse, "RMSE": rmse, "MAE": mae}

results = [train_and_evaluate(model, name, trainset, testset) for name, model in models.items()]
df_results = pd.DataFrame(results)

display(df_results)

"""## Deep learning

### Deep FM & NFM
"""

train_data = pd.read_csv("train_data.csv")
test_data = pd.read_csv("test_data.csv")

# Convert user_id and course_id to encoded integers
train_data["user_id"] = train_data["user_id"].astype("category").cat.codes
train_data["course_id"] = train_data["course_id"].astype("category").cat.codes
test_data["user_id"] = test_data["user_id"].astype("category").cat.codes
test_data["course_id"] = test_data["course_id"].astype("category").cat.codes

# Convert to PyTorch tensors
train_tensor = torch.tensor(train_data[["user_id", "course_id"]].values, dtype=torch.long)
train_labels = torch.tensor(train_data["rating"].values, dtype=torch.float32)
test_tensor = torch.tensor(test_data[["user_id", "course_id"]].values, dtype=torch.long)
test_labels = torch.tensor(test_data["rating"].values, dtype=torch.float32)

# number of unique users and items
num_users = max(train_data["user_id"].max(), test_data["user_id"].max()) + 1
num_items = max(train_data["course_id"].max(), test_data["course_id"].max()) + 1

# Function to create embeddings
def create_embeddings(num_users, num_items, embed_dim=16):
    return {
        "user_embedding": nn.Embedding(num_users, embed_dim),
        "item_embedding": nn.Embedding(num_items, embed_dim)
    }

# Function to create NeuralFM and DNN layers
def create_model(embed_dim=16, deep_layers=[64, 32], interaction_type="concat"):
    dnn_input_dim = embed_dim * 2 if interaction_type == "concat" else embed_dim
    fm_layer = nn.Linear(embed_dim * 2, 1)

    layers = []
    input_dim = dnn_input_dim
    for layer_size in deep_layers:
        layers.append(nn.Linear(input_dim, layer_size))
        layers.append(nn.ReLU())
        input_dim = layer_size
    layers.append(nn.Linear(input_dim, 1))

    return {
        "fm_layer": fm_layer,
        "dnn": nn.Sequential(*layers),
        "sigmoid": nn.Sigmoid(),
        "interaction_type": interaction_type
    }

# Forward pass function
def forward(user, item, embeddings, model):
    user_embed = embeddings["user_embedding"](user)
    item_embed = embeddings["item_embedding"](item)

    if model["interaction_type"] == "concat":
        interaction = torch.cat([user_embed, item_embed], dim=1)  # DeepFM
    else:
        interaction = user_embed * item_embed  # NFM

    fm_output = model["fm_layer"](torch.cat([user_embed, item_embed], dim=1))
    deep_output = model["dnn"](interaction)
    return model["sigmoid"](fm_output + deep_output).squeeze()

# Function to train and evaluate
def train_and_evaluate(embeddings, model, model_name, num_epochs=30, lr=0.01):
    criterion = nn.BCELoss()

    optimizer = optim.Adam(
        list(embeddings["user_embedding"].parameters()) +
        list(embeddings["item_embedding"].parameters()) +
        list(model["fm_layer"].parameters()) +
        list(model["dnn"].parameters()),
        lr=lr
    )

    for epoch in range(num_epochs):
        optimizer.zero_grad()
        outputs = forward(train_tensor[:, 0], train_tensor[:, 1], embeddings, model)
        loss = criterion(outputs, train_labels)
        loss.backward()
        optimizer.step()

        if (epoch + 1) % 5 == 0:
            print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

    print(f" {model_name} Training Completed")

    with torch.no_grad():
        predicted_ratings = forward(test_tensor[:, 0], test_tensor[:, 1], embeddings, model)

    true_ratings = test_labels.numpy()
    predicted_ratings = predicted_ratings.numpy()

    mse = mean_squared_error(true_ratings, predicted_ratings)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(true_ratings, predicted_ratings)

    print(f"\n {model_name} Evaluation Completed")
    print(f" MSE: {mse:.4f}")
    print(f" RMSE: {rmse:.4f}")
    print(f" MAE: {mae:.4f}")

# Initialize models
deepfm_embeddings = create_embeddings(num_users, num_items)
deepfm_model = create_model(interaction_type="concat")

nfm_embeddings = create_embeddings(num_users, num_items)
nfm_model = create_model(interaction_type="element-wise")

# Train and evaluate
train_and_evaluate(deepfm_embeddings, deepfm_model, "DeepFM")
train_and_evaluate(nfm_embeddings, nfm_model, "NeuralFM")

"""# Initial Results"""

# Define the evaluation results
results = {
    "Model": ["SVD", "KNN", "DeepFM", "NFM"],
    "MAE": [0.483579, 0.473815, 0.5008, 0.4997],
    "RMSE": [0.506084, 0.538316, 0.5205, 0.5139],
    "MSE": [ 0.256121, 0.289785, 0.2709, 0.2640]
}

# Create a DataFrame for comparison
df_results = pd.DataFrame(results)

# Display the table in Colab
from IPython.display import display
display(df_results)

# Define the evaluation results
results = {
    "Model": ["SVD", "KNN", "DeepFM", "NFM"],
    "MAE": [0.483579, 0.473815, 0.5008, 0.4997],
    "RMSE": [0.506084, 0.538316, 0.5205, 0.5139],
    "MSE": [ 0.256121, 0.289785, 0.2709, 0.2640]
}
# Create a DataFrame
df_results = pd.DataFrame(results)

plt.style.use("dark_background")

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Plot MAE
sns.barplot(x="Model", y="MAE", data=df_results, palette="cool", ax=axes[0])
axes[0].set_title("Mean Absolute Error (MAE)", fontsize=14, color="white")
axes[0].set_ylabel("MAE Value", fontsize=12, color="white")
axes[0].set_xlabel("Model", fontsize=12, color="white")

# Plot RMSE
sns.barplot(x="Model", y="RMSE", data=df_results, palette="magma", ax=axes[1])
axes[1].set_title("Root Mean Squared Error (RMSE)", fontsize=14, color="white")
axes[1].set_ylabel("RMSE Value", fontsize=12, color="white")
axes[1].set_xlabel("Model", fontsize=12, color="white")

# Plot MSE
sns.barplot(x="Model", y="MSE", data=df_results, palette="viridis", ax=axes[2])
axes[2].set_title("Mean Squared Error (MSE)", fontsize=14, color="white")
axes[2].set_ylabel("MSE Value", fontsize=12, color="white")
axes[2].set_xlabel("Model", fontsize=12, color="white")

for ax in axes:
    ax.spines["bottom"].set_color("white")
    ax.spines["left"].set_color("white")
    ax.tick_params(axis="x", colors="white")
    ax.tick_params(axis="y", colors="white")

plt.tight_layout()
plt.show()

"""*Best model now is SVD*

# Cross validation

## SVD & KNN
"""

train_data = pd.read_csv("train_data.csv")
reader = Reader(rating_scale=(0, 1))
data = Dataset.load_from_df(train_data[["user_id", "course_id", "rating"]], reader)

models = {
    "SVD": SVD(),
    "KNN": KNNBasic(sim_options={'name': 'pearson_baseline', 'user_based': True})
}

# Perform 5-Fold Cross-Validation for each model
cv_results = {}
for model_name, model in models.items():
    print(f"\n Performing Cross-Validation for {model_name}...")
    results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

    # Compute Mean MSE from RMSE
    mean_rmse = np.mean(results["test_rmse"])
    mean_mae = np.mean(results["test_mae"])
    mean_mse = mean_rmse ** 2

    # Store mean results
    cv_results[model_name] = {
        "Mean RMSE": mean_rmse,
        "Mean MAE": mean_mae,
        "Mean MSE": mean_mse
    }

# Convert results into DataFrame
df_cv_results = pd.DataFrame(cv_results).T
print("SVD & KNN Cross-Validation Results:")
display(df_cv_results)

# Load test data
test_data = pd.read_csv("test_data.csv")
testset = list(test_data[["user_id", "course_id", "rating"]].itertuples(index=False, name=None))

# Train best model on full training set
best_model_name = min(cv_results, key=lambda x: cv_results[x]["Mean RMSE"])
best_model = models[best_model_name]
trainset = data.build_full_trainset()
best_model.fit(trainset)

# Evaluate the model on the test set
predictions = best_model.test(testset)
true_ratings = np.array([rating for (_, _, rating) in testset])
predicted_ratings = np.array([pred.est for pred in predictions])
mse = mean_squared_error(true_ratings, predicted_ratings)
rmse = np.sqrt(mse)
mae = mean_absolute_error(true_ratings, predicted_ratings)

print(f"\n Final Test Set Evaluation:")
print(f" MSE: {mse:.4f}")
print(f" RMSE: {rmse:.4f}")
print(f" MAE: {mae:.4f}")

"""## DeepFN & NFN"""

# Load dataset
train_data = pd.read_csv("train_data.csv")

# Convert categorical user_id and course_id to encoded integers
train_data["user_id"] = train_data["user_id"].astype("category").cat.codes
train_data["course_id"] = train_data["course_id"].astype("category").cat.codes

# Convert data to PyTorch tensors
features = torch.tensor(train_data[["user_id", "course_id"]].values, dtype=torch.long)
labels = torch.tensor(train_data["rating"].values, dtype=torch.float32)

# Get the number of users and items
num_users = train_data["user_id"].max() + 1
num_items = train_data["course_id"].max() + 1

# Define K-Fold Cross-Validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Function to create embeddings
def create_embeddings(num_users, num_items, embed_dim=16):
    return {
        "user_embedding": nn.Embedding(num_users, embed_dim),
        "item_embedding": nn.Embedding(num_items, embed_dim)
    }

# Function to create FM and DNN layers
def create_model(embed_dim=16, deep_layers=[64, 32], interaction_type="concat"):
    dnn_input_dim = embed_dim * 2 if interaction_type == "concat" else embed_dim
    fm_layer = nn.Linear(embed_dim * 2, 1)

    layers = []
    input_dim = dnn_input_dim
    for layer_size in deep_layers:
        layers.append(nn.Linear(input_dim, layer_size))
        layers.append(nn.ReLU())
        input_dim = layer_size
    layers.append(nn.Linear(input_dim, 1))

    return {
        "fm_layer": fm_layer,
        "dnn": nn.Sequential(*layers),
        "sigmoid": nn.Sigmoid(),
        "interaction_type": interaction_type
    }

# Forward pass function
def forward(user, item, embeddings, model):
    user_embed = embeddings["user_embedding"](user)
    item_embed = embeddings["item_embedding"](item)

    if model["interaction_type"] == "concat":
        interaction = torch.cat([user_embed, item_embed], dim=1)  # DeepFM
    else:
        interaction = user_embed * item_embed  # NFM

    fm_output = model["fm_layer"](torch.cat([user_embed, item_embed], dim=1))
    deep_output = model["dnn"](interaction)
    return model["sigmoid"](fm_output + deep_output).squeeze()

# Function to train and evaluate with Cross-Validation
def train_and_evaluate_cv(embeddings, model, model_name, num_epochs=20, lr=0.01):
    criterion = nn.BCELoss()

    mse_scores, rmse_scores, mae_scores = [], [], []

    # K-Fold Cross-Validation Loop
    for fold, (train_idx, val_idx) in enumerate(kf.split(features)):
        print(f"\n Fold {fold+1}/{kf.get_n_splits()} - {model_name} Training...")

        train_features, val_features = features[train_idx], features[val_idx]
        train_labels, val_labels = labels[train_idx], labels[val_idx]

        optimizer = optim.Adam(
            list(embeddings["user_embedding"].parameters()) +
            list(embeddings["item_embedding"].parameters()) +
            list(model["fm_layer"].parameters()) +
            list(model["dnn"].parameters()),
            lr=lr
        )

        # Training Loop
        for epoch in range(num_epochs):
            optimizer.zero_grad()
            outputs = forward(train_features[:, 0], train_features[:, 1], embeddings, model)
            loss = criterion(outputs, train_labels)
            loss.backward()
            optimizer.step()

            if (epoch + 1) % 5 == 0:
                print(f"  Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

        print(f" Fold {fold+1} Training Completed!")

        # Evaluation
        with torch.no_grad():
            predicted_ratings = forward(val_features[:, 0], val_features[:, 1], embeddings, model)

        true_ratings = val_labels.numpy()
        predicted_ratings = predicted_ratings.numpy()

        mse = mean_squared_error(true_ratings, predicted_ratings)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(true_ratings, predicted_ratings)

        mse_scores.append(mse)
        rmse_scores.append(rmse)
        mae_scores.append(mae)

        print(f" Fold {fold+1} Evaluation Completed: MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}")

    # Calculate Mean Cross-Validation Scores
    avg_mse = np.mean(mse_scores)
    avg_rmse = np.mean(rmse_scores)
    avg_mae = np.mean(mae_scores)

    print(f"\n Final Cross-Validation Results for {model_name}:")
    print(f" Mean MSE: {avg_mse:.4f}")
    print(f" Mean RMSE: {avg_rmse:.4f}")
    print(f" Mean MAE: {avg_mae:.4f}")

    return {"Model": model_name, "MSE": avg_mse, "RMSE": avg_rmse, "MAE": avg_mae}

#  Train & Evaluate with Cross-Validation
deepfm_embeddings = create_embeddings(num_users, num_items)
deepfm_model = create_model(interaction_type="concat")

nfm_embeddings = create_embeddings(num_users, num_items)
nfm_model = create_model(interaction_type="element-wise")

deepfm_results = train_and_evaluate_cv(deepfm_embeddings, deepfm_model, "DeepFM")
nfm_results = train_and_evaluate_cv(nfm_embeddings, nfm_model, "NeuralFM")

#  Load test set
test_data = pd.read_csv("test_data.csv")
test_data["user_id"] = test_data["user_id"].astype("category").cat.codes
test_data["course_id"] = test_data["course_id"].astype("category").cat.codes

test_tensor = torch.tensor(test_data[["user_id", "course_id"]].values, dtype=torch.long)
test_labels = torch.tensor(test_data["rating"].values, dtype=torch.float32)

#  Train final model on full training data
def train_final_model(embeddings, model, num_epochs=20, lr=0.01):
    criterion = nn.BCELoss()
    optimizer = optim.Adam(
        list(embeddings["user_embedding"].parameters()) +
        list(embeddings["item_embedding"].parameters()) +
        list(model["fm_layer"].parameters()) +
        list(model["dnn"].parameters()),
        lr=lr
    )

    for epoch in range(num_epochs):
        optimizer.zero_grad()
        outputs = forward(features[:, 0], features[:, 1], embeddings, model)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

# Train & Evaluate on `test_data.csv`
train_final_model(deepfm_embeddings, deepfm_model)
train_final_model(nfm_embeddings, nfm_model)

def evaluate_final_model(embeddings, model, model_name):
    with torch.no_grad():
        predicted_ratings = forward(test_tensor[:, 0], test_tensor[:, 1], embeddings, model)

    mse = mean_squared_error(test_labels.numpy(), predicted_ratings.numpy())
    print(f"\n Final Test Set Evaluation for {model_name}: MSE: {mse:.4f}")

evaluate_final_model(deepfm_embeddings, deepfm_model, "DeepFM")
evaluate_final_model(nfm_embeddings, nfm_model, "NeuralFM")

"""# Results for cross validation"""

# Define Pre-CV and Post-CV results
models = ["SVD", "KNN", "DeepFM", "NFM"]
pre_cv_mse = [0.256121, 0.289785, 0.2709, 0.2640]  # Before Cross-Validation
post_cv_mse = [0.259482, 0.305530, 0.2253, 0.2105]  # After Cross-Validation

df_mse = pd.DataFrame({"Model": models, "Pre-CV MSE": pre_cv_mse, "Post-CV MSE": post_cv_mse})

plt.style.use("dark_background")
plt.figure(figsize=(10, 6))

# Bar plot
bar_width = 0.4
x = np.arange(len(models))

plt.bar(x - bar_width/2, pre_cv_mse, bar_width, label="Pre-CV MSE", color="blue", alpha=0.7)
plt.bar(x + bar_width/2, post_cv_mse, bar_width, label="Post-CV MSE", color="red", alpha=0.7)

plt.xlabel("Model", fontsize=12)
plt.ylabel("Mean Squared Error (MSE)", fontsize=12)
plt.title("Comparison of MSE Before and After Cross-Validation", fontsize=14)
plt.xticks(x, models)
plt.legend()
plt.grid(axis="y", linestyle="--", alpha=0.7)

plt.show()

from tabulate import tabulate
print("\n MSE Comparison Before & After Cross-Validation:")
print(tabulate(df_mse, headers="keys", tablefmt="pretty"))

"""### *Best model now is NFM*

# Hyperparameter tuning

## SVD & KNN
"""

#  Load Training Data
train_data = pd.read_csv("train_data.csv")
reader = Reader(rating_scale=(0, 1))
data = Dataset.load_from_df(train_data[["user_id", "course_id", "rating"]], reader)

#  Hyperparameter Grid for SVD
svd_param_grid = {
    "n_factors": [5, 10],
    "lr_all": [0.0001, 0.0005],
    "reg_all": [0.5, 1.0]
}

#  Perform Grid Search for SVD
print("\n Performing Hyperparameter Tuning for SVD...")
svd_gs = GridSearchCV(SVD, svd_param_grid, measures=["rmse", "mae"], cv=5, n_jobs=-1)
svd_gs.fit(data)

best_svd_params = svd_gs.best_params["rmse"]
print("\n Best SVD Parameters:", best_svd_params)

# Define Hyperparameter Grid for KNN
knn_param_grid = {
    'k': [1, 5],
    'sim_options': {
        'name': ['pearson'],
        'user_based': [True],
        'min_support': [3]
    }
}

# Perform Grid Search for KNN
print("\n Performing Hyperparameter Tuning for KNN...")
knn_gs = GridSearchCV(KNNBasic, knn_param_grid, measures=["rmse", "mae"], cv=5, n_jobs=-1)
knn_gs.fit(data)

best_knn_params = knn_gs.best_params["rmse"]
print("\n Best KNN Parameters:", best_knn_params)

# Load Test Data
test_data = pd.read_csv("test_data.csv")
testset = list(test_data[["user_id", "course_id", "rating"]].itertuples(index=False, name=None))

# Train Final Model on Full Training Set
trainset = data.build_full_trainset()

# Train best SVD model on full dataset
best_svd = SVD(**best_svd_params)
best_svd.fit(trainset)

# Train best KNN model on full dataset
best_knn = KNNBasic(k=best_knn_params["k"], sim_options=best_knn_params["sim_options"])
best_knn.fit(trainset)

#  Evaluate Models on test_data.csv
def evaluate_model(model, testset, model_name):
    predictions = model.test(testset)

    # Compute RMSE, MAE, and MSE
    test_rmse = accuracy.rmse(predictions)
    test_mae = accuracy.mae(predictions)
    test_mse = test_rmse ** 2

    print(f"\n Final Test Set Evaluation for {model_name}:")
    print(f" MSE: {test_mse:.4f}")
    print(f" RMSE: {test_rmse:.4f}")
    print(f" MAE: {test_mae:.4f}")

    return {"Model": model_name, "MSE": test_mse, "RMSE": test_rmse, "MAE": test_mae}

# Evaluate both models on the real test set
svd_test_results = evaluate_model(best_svd, testset, "SVD")
knn_test_results = evaluate_model(best_knn, testset, "KNN")

df_best_params = pd.DataFrame({
    "Model": ["SVD", "KNN"],
    "Best RMSE (CV)": [svd_gs.best_score["rmse"], knn_gs.best_score["rmse"]],
    "Best MSE (CV)": [svd_gs.best_score["rmse"] ** 2, knn_gs.best_score["rmse"] ** 2],
    "Best MAE (CV)": [svd_gs.best_score["mae"], knn_gs.best_score["mae"]],
    "Best Params": [str(best_svd_params), str(best_knn_params)]
})

df_test_results = pd.DataFrame([svd_test_results, knn_test_results])

print("\n Best Hyperparameter Results (Cross-Validation):")
print(tabulate(df_best_params, headers="keys", tablefmt="pretty"))

"""## Neural FM and Deep FM"""

train_data = pd.read_csv("train_data.csv")

train_data["user_id"] = train_data["user_id"].astype("category").cat.codes
train_data["course_id"] = train_data["course_id"].astype("category").cat.codes

features = torch.tensor(train_data[["user_id", "course_id"]].values, dtype=torch.long)
labels = torch.tensor(train_data["rating"].values, dtype=torch.float32)

num_users = train_data["user_id"].max() + 1
num_items = train_data["course_id"].max() + 1

#  Cross-Validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Function to create embeddings
def create_embeddings(num_users, num_items, embed_dim):
    return {
        "user_embedding": nn.Embedding(num_users, embed_dim),
        "item_embedding": nn.Embedding(num_items, embed_dim)
    }

# Function to create FM and DNN layers
def create_model(embed_dim, deep_layers, interaction_type):
    dnn_input_dim = embed_dim * 2 if interaction_type == "concat" else embed_dim
    fm_layer = nn.Linear(embed_dim * 2, 1)

    layers = []
    input_dim = dnn_input_dim
    for layer_size in deep_layers:
        layers.append(nn.Linear(input_dim, layer_size))
        layers.append(nn.ReLU())
        input_dim = layer_size
    layers.append(nn.Linear(input_dim, 1))

    return {
        "fm_layer": fm_layer,
        "dnn": nn.Sequential(*layers),
        "sigmoid": nn.Sigmoid(),
        "interaction_type": interaction_type
    }

# Forward pass function
def forward(user, item, embeddings, model):
    user_embed = embeddings["user_embedding"](user)
    item_embed = embeddings["item_embedding"](item)

    if model["interaction_type"] == "concat":
        interaction = torch.cat([user_embed, item_embed], dim=1)  # DeepFM
    else:
        interaction = user_embed * item_embed  # NFM

    fm_output = model["fm_layer"](torch.cat([user_embed, item_embed], dim=1))
    deep_output = model["dnn"](interaction)
    return model["sigmoid"](fm_output + deep_output).squeeze()

# Function to train and evaluate with Cross-Validation
def train_and_evaluate_cv(embeddings, model, model_name, num_epochs, lr):
    criterion = nn.BCELoss()
    mse_scores, rmse_scores, mae_scores = [], [], []

    for fold, (train_idx, val_idx) in enumerate(kf.split(features)):
        print(f"\n Fold {fold+1}/{kf.get_n_splits()} - {model_name} Training...")

        train_features, val_features = features[train_idx], features[val_idx]
        train_labels, val_labels = labels[train_idx], labels[val_idx]

        optimizer = optim.Adam(
            list(embeddings["user_embedding"].parameters()) +
            list(embeddings["item_embedding"].parameters()) +
            list(model["fm_layer"].parameters()) +
            list(model["dnn"].parameters()),
            lr=lr
        )

        for epoch in range(num_epochs):
            optimizer.zero_grad()
            outputs = forward(train_features[:, 0], train_features[:, 1], embeddings, model)
            loss = criterion(outputs, train_labels)
            loss.backward()
            optimizer.step()

            if (epoch + 1) % 5 == 0:
                print(f"  Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

        print(f" Fold {fold+1} Training Completed!")

        with torch.no_grad():
            predicted_ratings = forward(val_features[:, 0], val_features[:, 1], embeddings, model)

        true_ratings = val_labels.numpy()
        predicted_ratings = predicted_ratings.numpy()

        mse = mean_squared_error(true_ratings, predicted_ratings)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(true_ratings, predicted_ratings)

        mse_scores.append(mse)
        rmse_scores.append(rmse)
        mae_scores.append(mae)

    avg_mse = np.mean(mse_scores)
    avg_rmse = np.mean(rmse_scores)
    avg_mae = np.mean(mae_scores)

    print(f"\n Final Cross-Validation Results for {model_name}:")
    print(f" Mean MSE: {avg_mse:.4f}")
    print(f" Mean RMSE: {avg_rmse:.4f}")
    print(f" Mean MAE: {avg_mae:.4f}")

    return {"Model": model_name, "MSE": avg_mse, "RMSE": avg_rmse, "MAE": avg_mae}

# Define Hyperparameter Grid
param_grid = {
    "embed_dim": [16, 32],
    "deep_layers": [[64, 32], [128, 64]],
    "learning_rate": [0.001, 0.005],
    "num_epochs": [20, 30]
}

best_results = []

for params in ParameterGrid(param_grid):
    print(f"\n Testing Hyperparameters: {params}")

    deepfm_embeddings = create_embeddings(num_users, num_items, params["embed_dim"])
    deepfm_model = create_model(params["embed_dim"], params["deep_layers"], interaction_type="concat")
    deepfm_results = train_and_evaluate_cv(deepfm_embeddings, deepfm_model, "DeepFM", params["num_epochs"], params["learning_rate"])

    nfm_embeddings = create_embeddings(num_users, num_items, params["embed_dim"])
    nfm_model = create_model(params["embed_dim"], params["deep_layers"], interaction_type="element-wise")
    nfm_results = train_and_evaluate_cv(nfm_embeddings, nfm_model, "NeuralFM", params["num_epochs"], params["learning_rate"])

    best_results.append({
        "Hyperparams": params,
        "DeepFM_MSE": deepfm_results["MSE"],
        "DeepFM_RMSE": deepfm_results["RMSE"],
        "DeepFM_MAE": deepfm_results["MAE"],
        "NFM_MSE": nfm_results["MSE"],
        "NFM_RMSE": nfm_results["RMSE"],
        "NFM_MAE": nfm_results["MAE"]
    })

# Convert results into a DataFrame
df_best_results = pd.DataFrame(best_results)

# Find the best hyperparameters for DeepFM and NFM (based on lowest MSE)
best_deepfm_row = df_best_results.loc[df_best_results["DeepFM_MSE"].idxmin()]
best_nfm_row = df_best_results.loc[df_best_results["NFM_MSE"].idxmin()]

# Extract best parameters & scores for each model
best_deepfm_params = best_deepfm_row["Hyperparams"]
best_nfm_params = best_nfm_row["Hyperparams"]

# Format the final table
df_best_models = pd.DataFrame({
    "Model": ["DeepFM", "NeuralFM"],
    "Best RMSE": [best_deepfm_row["DeepFM_RMSE"], best_nfm_row["NFM_RMSE"]],
    "Best MSE": [best_deepfm_row["DeepFM_MSE"], best_nfm_row["NFM_MSE"]],
    "Best MAE": [best_deepfm_row["DeepFM_MAE"], best_nfm_row["NFM_MAE"]],
    "Best Params": [str(best_deepfm_params), str(best_nfm_params)]
})

# Print results in a structured format
print("\n Best Hyperparameter Results for DeepFM & NFM:")
print(tabulate(df_best_models, headers="keys", tablefmt="pretty"))

"""# Results of Hyperparameter Tuning"""

# Data for models' performance
models = ["DeepFM", "NeuralFM", "SVD", "KNN"]
rmse_values = [ 0.4547, 0.4307, 0.49686, 0.5637]
mse_values = [0.2090, 0.1900, 0.2468, 0.3177]
mae_values = [0.3954,  0.35728, 0.4945, 0.4772]

# Create DataFrame
df_results = pd.DataFrame({
    "Model": models,
    "Best RMSE": rmse_values,
    "Best MSE": mse_values,
    "Best MAE": mae_values
})

sns.set(style="darkgrid")
plt.style.use("dark_background")

# Plot RMSE Comparison
plt.figure(figsize=(10, 5))
sns.barplot(x=models, y=rmse_values, palette="coolwarm")
plt.xlabel("Model", fontsize=12)
plt.ylabel("RMSE", fontsize=12)
plt.title("Model Comparison - RMSE", fontsize=14)
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# Plot MSE Comparison
plt.figure(figsize=(10, 5))
sns.barplot(x=models, y=mse_values, palette="coolwarm")
plt.xlabel("Model", fontsize=12)
plt.ylabel("MSE", fontsize=12)
plt.title("Model Comparison - MSE", fontsize=14)
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# Plot MAE Comparison
plt.figure(figsize=(10, 5))
sns.barplot(x=models, y=mae_values, palette="coolwarm")
plt.xlabel("Model", fontsize=12)
plt.ylabel("MAE", fontsize=12)
plt.title("Model Comparison - MAE", fontsize=14)
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

print("\nModel Performance Comparison:")
display(df_results)

"""***NeuralFM is the best model***

*Recommendation (Testing function)*
"""

# Load meal metadata
course_df = pd.read_csv("extracted_course/course_cleaned.csv")
print("Checking available columns in dataset:", course_df.columns)
print(" Checking category column values:\n", course_df["category"].head(10))
course_df["category"] = course_df["category"].str.lower()

# Define sugar, fiber, and calorie thresholds
sugar_thresholds = {
    "high": {"max_sugar": 15, "max_calories": 350, "min_fiber": 2},
    "normal": {"max_sugar": 30, "max_calories": 500, "min_fiber": 1.5},
    "low": {"max_sugar": 40, "max_calories": 700, "min_fiber": 1}
}

def classify_sugar_level(sugar_value):
    if sugar_value > 180:
        return "high"
    elif 100 <= sugar_value <= 180:
        return "normal"
    else:
        return "low"

def filter_meals_by_sugar(user_sugar_level, recommended_meals):
    thresholds = sugar_thresholds[user_sugar_level]

    # Apply filtering
    filtered_meals = recommended_meals[
        (recommended_meals["sugar"] <= thresholds["max_sugar"]) &
        (recommended_meals["calories"] <= thresholds["max_calories"]) &
        (recommended_meals["fiber"] >= thresholds["min_fiber"])
    ]

    if len(filtered_meals) < 3:
        print("\n Few meals passed filtering. Relaxing sugar limit slightly...")
        relaxed_threshold = thresholds["max_sugar"] + 5
        filtered_meals = recommended_meals[recommended_meals["sugar"] <= relaxed_threshold]

    if filtered_meals.empty:
        print("\n No meals matched. Showing lowest sugar meals instead.")
        filtered_meals = recommended_meals.nsmallest(5, "sugar")

    return filtered_meals

def get_neuralfm_recommendations(user_id, top_n=10):
    user_tensor = torch.tensor([user_id] * num_items, dtype=torch.long)
    item_tensor = torch.arange(num_items, dtype=torch.long)

    with torch.no_grad():
        scores = forward(user_tensor, item_tensor, nfm_embeddings, nfm_model)

    top_meal_indices = torch.argsort(scores, descending=True)[:top_n].tolist()

    recommended_meals = course_df.iloc[top_meal_indices]
    return recommended_meals

# User login and sugar input
user_id = int(input("Enter your User ID: "))
sugar_value = float(input("Enter your sugar level (mg/dL): "))
user_sugar_level = classify_sugar_level(sugar_value)

# Get meal recommendations using NeuralFM
recommended_meals = get_neuralfm_recommendations(user_id)

print("\n Raw Recommendations from NeuralFM:")
print(recommended_meals[["course_name", "calories", "sugar", "fiber", "category", "image_url"]])

# Apply sugar-based filtering
filtered_meals = filter_meals_by_sugar(user_sugar_level, recommended_meals)

filtered_meals = filtered_meals.copy()

appetizers = filtered_meals[filtered_meals["category"] == "appetizer"]
main_dishes = filtered_meals[filtered_meals["category"] == "main-dish"]
desserts = filtered_meals[filtered_meals["category"] == "dessert"]

# Display final recommendations
print("\n Final Diabetes-Friendly Meal Recommendations:\n")

def display_meals(meals, category_name, emoji):
    if not meals.empty:
        print(f"\n{emoji} **{category_name}:**")
        for _, row in meals.iterrows():
            print(f" {row['course_name']}")
            print(f"   - Calories: {row['calories']:.2f}, Sugar: {row['sugar']:.2f}g, Fiber: {row['fiber']:.2f}g")
            print(f"   - Ingredients: {row['ingredients'][:100]}...")
            print(f"   - Recipe: {row['cooking_directions'][:100]}...")
            print(f"   -  Image: {row['image_url']}\n")

# Display categorized meals with images
display_meals(appetizers, "Appetizers", "")
display_meals(main_dishes, "Main Dishes", "")
display_meals(desserts, "Desserts", "")

"""# Save model"""

# Save individual components separately
torch.save(nfm_model["fm_layer"].state_dict(), "nfm_fm_layer.pth")
torch.save(nfm_model["dnn"].state_dict(), "nfm_dnn.pth")

# Save embeddings separately
torch.save(nfm_embeddings["user_embedding"].state_dict(), "nfm_user_embedding.pth")
torch.save(nfm_embeddings["item_embedding"].state_dict(), "nfm_item_embedding.pth")

# Download all files
from google.colab import files
files.download("nfm_fm_layer.pth")
files.download("nfm_dnn.pth")
files.download("nfm_user_embedding.pth")
files.download("nfm_item_embedding.pth")

print(" Model components saved and ready for download!")

files.download("nfm_fm_layer.pth")
files.download("nfm_dnn.pth")
files.download("nfm_user_embedding.pth")
files.download("nfm_item_embedding.pth")

"""Sign Up/Login (Testing function)"""

file_path = "filtered_df.csv"
df = pd.read_csv(file_path)

#  user_id is treated as an integer
df["user_id"] = df["user_id"].astype(int)

def ask_sugar_level():
    while True:
        try:
            sugar_level = float(input("Enter your sugar level (mg/dL): ").strip())
            print(f" Sugar level recorded: {sugar_level} mg/dL (temporary value).")
            return sugar_level
        except ValueError:
            print(" Invalid input. Please enter a numeric value.")

def sign_in():
    user_name = input("Enter your name: ").strip()

    # Check if the user exists
    if user_name in df["Name"].values:
        user_id = df[df["Name"] == user_name]["user_id"].iloc[0]
        print(f" Welcome back, {user_name}! Your User ID is {user_id}.")

        # Ask for sugar level (temporary storage)
        sugar_level = ask_sugar_level()

    else:
        print(" User not found. Please sign up.")

def sign_up():
    user_name = input("Enter a new username: ").strip()

    # Check if username already exists
    if user_name in df["Name"].values:
        print(" This username already exists. Try signing in.")
        return

    # Assign new user_id (last user_id + 1)
    new_user_id = df["user_id"].max() + 1

    new_user = pd.DataFrame({"user_id": [new_user_id], "Name": [user_name]})
    df_new = pd.concat([df, new_user], ignore_index=True)

    df_new.to_csv(file_path, index=False)

    print(f" User {user_name} created successfully! Your User ID is {new_user_id}.")

    # Ask for sugar level (temporary storage)
    sugar_level = ask_sugar_level()

# Ask user if they want to sign in or sign up
choice = input("Do you want to Sign In or Sign Up? (Enter 'in' or 'up'): ").strip().lower()

if choice == "in":
    sign_in()
elif choice == "up":
    sign_up()
else:
    print(" Invalid choice. Please restart the program.")